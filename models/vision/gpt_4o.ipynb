{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import base64\n",
    "import re\n",
    "from IPython.display import display, Markdown,Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取环境变量\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_endpoint = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "langchain_project = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "api_key=os.getenv(\"API_KEY\")\n",
    "base_url=os.getenv(\"BASE_URL\")\n",
    "# deepseek_api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# deepseek_base_url=os.getenv(\"DEEPSEEK_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputPrompt (question):\n",
    "       \n",
    "    # 构建系统消息\n",
    "    system_message = SystemMessage(\n",
    "        content=\"You are a financial expert. You will be given questions and options, possibly with context information and images. Please answer the question.\"\n",
    "    )\n",
    "\n",
    "    # 构建用户消息\n",
    "    human_message=HumanMessage(content=[])\n",
    "\n",
    "    if len(question[\"Share Context\"]) != 0:\n",
    "        human_message.content.append({\"type\": \"text\", \"text\": \"Context: \" + question[\"Share Context\"]})\n",
    "\n",
    "    if len(question[\"Share Image\"])!= 0:\n",
    "        for path in question[\"Share Image\"]:\n",
    "            image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+path\n",
    "            with open(image_url, \"rb\") as image_file:\n",
    "                image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "            human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Question: \"+ question[\"Question Text\"]})\n",
    "\n",
    "    if len(question[\"Image\"]) != 0:\n",
    "        image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+question[\"Image\"]\n",
    "        with open(image_url, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Options: \" + str(question[\"Options\"])})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Let's think step by step. The output reasoning steps are in Markdown format. Finally, must put the correct option (A, B, C, or D) in【 】. e.g.Therefore, the correct option is 【B】.\"})\n",
    "\n",
    "    response = [system_message, human_message]\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "##Utils\n",
    "def FeedbackPrompt (question):\n",
    "       \n",
    "    system_message = SystemMessage(\n",
    "            content=\"\"\"You are a financial expert. You will be given questions and options, possibly with context information and images. Also, you will be given wrong reasoning steps and correct reasoning hints.You are supposed to give feedback.\"\"\")\n",
    "\n",
    "    # 构建用户消息\n",
    "    human_message=HumanMessage(content=[])\n",
    "\n",
    "    if len(question[\"Share Context\"]) != 0:\n",
    "        human_message.content.append({\"type\": \"text\", \"text\": \"Context: \" + question[\"Share Context\"]})\n",
    "\n",
    "    if len(question[\"Share Image\"])!= 0:\n",
    "        for path in question[\"Share Image\"]:\n",
    "            image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+path\n",
    "            with open(image_url, \"rb\") as image_file:\n",
    "                image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "            human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Question: \"+ question[\"Question Text\"]})\n",
    "\n",
    "    if len(question[\"Image\"]) != 0:\n",
    "        image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+question[\"Image\"]\n",
    "        with open(image_url, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Options: \" + str(question[\"Options\"])})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Wrong Reasoning Steps: \" + question[\"Model Reasoning\"]})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Wrong Answer: \" + question[\"Model Answer\"]})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Correct Reasoning Steps: \" + question[\"Explanation\"]})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Correct Answer: \" + question[\"Answer\"]})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"\"\" Please give the feedback in Markdown format. 1. Please output correct reasoning steps according to hints. 2. compare the correct reasoning step with the model's wrong reasoning step, and point out the difference. 3. summarize the hint for future simalar questions.\"\"\"})\n",
    "\n",
    "    response = [system_message, human_message]\n",
    "    return response\n",
    "\n",
    "\n",
    "def ICLPrompt (question,example):\n",
    "       \n",
    "    # 构建系统消息\n",
    "    system_message = SystemMessage(\n",
    "        content=\"You are a financial expert. You will be given previous learning document including questions and options, possibly with context information and images. Please answer the current question.\"\n",
    "    )\n",
    "\n",
    "    # 构建用户消息\n",
    "    human_message=HumanMessage(content=[])\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Previous Learning Document: \"})\n",
    "    if len(example[\"Share Context\"]) != 0:\n",
    "        human_message.content.append({\"type\": \"text\", \"text\": \"Context: \" + example[\"Share Context\"]})\n",
    "\n",
    "    if len(example[\"Share Image\"])!= 0:\n",
    "        for path in example[\"Share Image\"]:\n",
    "            image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+path\n",
    "            with open(image_url, \"rb\") as image_file:\n",
    "                image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "            human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Question: \"+ example[\"Question Text\"]})\n",
    "\n",
    "    if len(example[\"Image\"]) != 0:\n",
    "        image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+example[\"Image\"]\n",
    "        with open(image_url, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Options: \" + str(example[\"Options\"])})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Wrong Reasoning Steps: \" + example[\"Model Reasoning\"]})\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Feedback: \" + example[\"Feedback\"]})\n",
    "\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Current Question is as follows: \"})\n",
    "    if len(question[\"Share Context\"]) != 0:\n",
    "        human_message.content.append({\"type\": \"text\", \"text\": \"Context: \" + question[\"Share Context\"]})\n",
    "\n",
    "    if len(question[\"Share Image\"])!= 0:\n",
    "        for path in question[\"Share Image\"]:\n",
    "            image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+path\n",
    "            with open(image_url, \"rb\") as image_file:\n",
    "                image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "            human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Question: \"+ question[\"Question Text\"]})\n",
    "\n",
    "    if len(question[\"Image\"]) != 0:\n",
    "        image_url = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+question[\"Image\"]\n",
    "        with open(image_url, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        human_message.content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Options: \" + str(question[\"Options\"])})\n",
    "\n",
    "    human_message.content.append({\"type\": \"text\", \"text\": \"Let's think step by step. The output reasoning steps are in Markdown format. Finally, must put the correct option (A, B, C, or D) in【 】. e.g.Therefore, the correct option is 【B】.\"})\n",
    "\n",
    "    response = [system_message, human_message]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
    "from langchain_core.outputs import Generation\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "class MarkdownParser(BaseGenerationOutputParser[str]):\n",
    "    \"\"\"\n",
    "    A custom parser that formats the model output for Markdown display\n",
    "    by replacing LaTeX-style delimiters \\[ and \\] with $.\n",
    "    \"\"\"\n",
    "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
    "        \"\"\"Parse the model output and format it as Markdown.\n",
    "\n",
    "        Args:\n",
    "            result: A list of Generations (assumed to contain only one string).\n",
    "            partial: Whether to allow partial results (for streaming, not used here).\n",
    "\n",
    "        Returns:\n",
    "            A Markdown-formatted string with LaTeX-style delimiters replaced.\n",
    "        \"\"\"\n",
    "        # Ensure there's only one generation\n",
    "        if len(result) != 1:\n",
    "            raise ValueError(\"This parser only supports a single generation.\")\n",
    "        \n",
    "        # Extract the generation content\n",
    "        generation = result[0]\n",
    "        if not isinstance(generation.text, str):\n",
    "            raise ValueError(\"Expected text output for Markdown formatting.\")\n",
    "        \n",
    "        # Replace  \\\\[ and \\\\] with $ for LaTeX-style display\n",
    "        formatted_text = generation.text.replace('\\\\[', '$').replace('\\\\]', '$').replace('\\\\(', '$').replace('\\\\)', '$')\n",
    "        \n",
    "        import re\n",
    "\n",
    "\n",
    "\n",
    "        return formatted_text\n",
    "    \n",
    "\n",
    "import re\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def extract_answer(text: str) -> str:\n",
    "    \"\"\"Extract the answer option (A, B, C, or D) in brackets from the given text.\"\"\"\n",
    "    # Regular expression to find the answer in brackets, e.g., [C]\n",
    "    match = re.search(r\"\\【([A-D])\\】\", text)\n",
    "    if match:\n",
    "        return match.group(1)  # Returns the answer option (e.g., \"C\")\n",
    "    else:\n",
    "        return \"Answer not found\"  # Returns a message if no answer is found\n",
    "\n",
    "# Wrap extract_answer in a LangChain Tool to make it invokable\n",
    "extract_answer_tool = Tool.from_function(\n",
    "    func=extract_answer,\n",
    "    name=\"Extract Answer Tool\",\n",
    "    description=\"Extracts the answer option in brackets (e.g., 【C】) from the provided text.\"\n",
    ")\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def write_output(data, file_path):\n",
    "    # 如果文件存在，先读取现有数据\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        existing_data = []\n",
    "\n",
    "    # 合并新数据到现有数据中\n",
    "    if isinstance(existing_data, list):\n",
    "        existing_data.append(data)\n",
    "    else:\n",
    "        existing_data = data\n",
    "\n",
    "    # 将合并后的数据写入到 JSON 文件\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "LLMmodel = ChatOpenAI(model=\"gpt-4o\", api_key=os.getenv(\"API_KEY\"), base_url=os.getenv(\"BASE_URL\"))\n",
    "outputParser=MarkdownParser()\n",
    "chain = LLMmodel|outputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置文件路径\n",
    "ErrorLogPath=\"/Volumes/Jennie/Reasoning/FinReasoning/errorLog/gpt_4o_ErrorLog.json\"\n",
    "ModelOutputPath=\"/Volumes/Jennie/Reasoning/FinReasoning/output/gpt_4o_output.json\"\n",
    "ModelRAGOutputPath=\"/Volumes/Jennie/Reasoning/FinReasoning/output/gpt_4o_rag_output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 0,\n",
       "  'Question Number': 1,\n",
       "  'Share Context': 'Neshie Wakuluk is an investment strategist who develops capital market expectations for\\nan investment firm that invests across asset classes and global markets. Wakuluk started her\\ncareer when the global markets were experiencing significant volatility and poor returns; as a\\nresult, she is now careful to base her conclusions on objective evidence and analytical\\nprocedures to mitigate any potential biases.Wakuluk’s approach to economic forecasting\\nutilizes a structural model in conjunction with a diffusion index to determine the current\\nphase of a country’s business cycle. This approach has produced successful predictions in the\\npast, thus Wakuluk has high confidence in the predictions. Wakuluk also determines whether any\\nadjustments need to be made to her initial estimates of the respective aggregate economic\\ngrowth trends based on historical rates of growth for Countries X and Y (both developed\\nmarkets) and Country Z (a developing market). Exhibit 1 summarizes Wakuluk’s predictions:\\nWakuluk assumes short-term interest rates adjust with expected inflation and are procyclical.\\nWakuluk reviews the historical short-term interest rate trends for each country, which further\\nconfirms her predictions shown in Exhibit 1.Wakuluk decides to focus on Country Y to determine\\nthe path of nominal interest rates, the potential economic response of Country Y’s economy to\\nthis path, and the timing for when Country Y’s economy may move into the next business cycle.\\nWakuluk makes the following observations:Observation 1 Monetary policy has been persistently\\nloose for Country Y, while fiscal policies have been persistently tight.Observation 2 Country Y\\nis expected to significantly increase transfer payments and introduce a more progressive tax\\nregime.Observation 3 The current yield curve for Country Y suggests that the business cycle is\\nin the slowdown phase, with bond yields starting to reflect contractionary conditions.\\n ',\n",
       "  'Share Image': \"['images/CapitalMarketExpectations_images/share1-8_1.png']\",\n",
       "  'Question Text': 'Wakuluk most likely seeks to mitigate which of the following biases in',\n",
       "  'Image': '',\n",
       "  'Options': \"{'A': 'Availability', 'B': 'Time period', 'C': 'Survivorship'}\",\n",
       "  'Answer': 'A',\n",
       "  'Explanation': 'Wakuluk started her career when the global markets were experiencing significant\\nvolatility and poor returns. She is careful to base her conclusions on objective evidence and\\nanalytical procedures to mitigate potential biases, which suggests she is seeking to mitigate\\nan availability bias. Availability bias is the tendency to be overly influenced by events that\\nhave left a strong impression and/or for which it is easy to recall an example.',\n",
       "  'QA Type': 'Knowledge Reasoning QA',\n",
       "  'Question Type': 'text+image',\n",
       "  'Level of Difficulty': 'Easy',\n",
       "  'Knowledge Topics': 'Behavioral finance, Cognitive biases, Decision-making processes',\n",
       "  'General Topics': 'Capital Market Expectations',\n",
       "  'Book Label': 'Capital Market Expectations',\n",
       "  'Model Answer': 'B',\n",
       "  'Model Reasoning': \"To determine which bias Wakuluk seeks to mitigate, let's analyze the context:\\n\\n1. **Objective Evidence and Analytical Procedures**: Wakuluk bases her conclusions on objective evidence and analytical procedures. This suggests she aims to avoid biases that can arise from subjective or limited data.\\n\\n2. **Historical Growth Rates and Market Conditions**: She uses historical rates of growth and considers past market conditions. This indicates she is conscious of biases that can result from focusing on a narrow or unrepresentative time frame.\\n\\n3. **Bias Types**:\\n   - **Availability Bias**: This bias occurs when decisions are based on information that is readily available, rather than all relevant information.\\n   - **Time Period Bias**: This bias arises from using data from a time period that may not represent the current or future environment. It involves relying on data that may be too short or not reflective of different market conditions.\\n   - **Survivorship Bias**: This bias occurs when only successful entities are considered, ignoring those that have failed.\\n\\nGiven Wakuluk's focus on using comprehensive historical data and her analytical approach, she is likely trying to mitigate the **Time Period Bias**. This is because she wants to ensure her forecasts and decisions are not overly influenced by a limited or unrepresentative historical period.\\n\\nTherefore, the correct option is 【B】.\",\n",
       "  'Filter': 1,\n",
       "  'shared_description': '',\n",
       "  'description': '',\n",
       "  '待处理': '',\n",
       "  'Train': ''},\n",
       " {'ID': 4,\n",
       "  'Question Number': 5,\n",
       "  'Share Context': 'Neshie Wakuluk is an investment strategist who develops capital market expectations for\\nan investment firm that invests across asset classes and global markets. Wakuluk started her\\ncareer when the global markets were experiencing significant volatility and poor returns; as a\\nresult, she is now careful to base her conclusions on objective evidence and analytical\\nprocedures to mitigate any potential biases.Wakuluk’s approach to economic forecasting\\nutilizes a structural model in conjunction with a diffusion index to determine the current\\nphase of a country’s business cycle. This approach has produced successful predictions in the\\npast, thus Wakuluk has high confidence in the predictions. Wakuluk also determines whether any\\nadjustments need to be made to her initial estimates of the respective aggregate economic\\ngrowth trends based on historical rates of growth for Countries X and Y (both developed\\nmarkets) and Country Z (a developing market). Exhibit 1 summarizes Wakuluk’s predictions:\\nWakuluk assumes short-term interest rates adjust with expected inflation and are procyclical.\\nWakuluk reviews the historical short-term interest rate trends for each country, which further\\nconfirms her predictions shown in Exhibit 1.Wakuluk decides to focus on Country Y to determine\\nthe path of nominal interest rates, the potential economic response of Country Y’s economy to\\nthis path, and the timing for when Country Y’s economy may move into the next business cycle.\\nWakuluk makes the following observations:Observation 1 Monetary policy has been persistently\\nloose for Country Y, while fiscal policies have been persistently tight.Observation 2 Country Y\\nis expected to significantly increase transfer payments and introduce a more progressive tax\\nregime.Observation 3 The current yield curve for Country Y suggests that the business cycle is\\nin the slowdown phase, with bond yields starting to reflect contractionary conditions.\\n ',\n",
       "  'Share Image': \"['images/CapitalMarketExpectations_images/share1-8_1.png']\",\n",
       "  'Question Text': 'Based on Exhibit 1, what capital market effect is Country Z most likely to',\n",
       "  'Image': '',\n",
       "  'Options': \"{'A': 'Cyclical assets attract investors.', 'B': 'Monetary policy becomes restrictive.', 'C': 'The yield curve steepens substantially.'}\",\n",
       "  'Answer': 'B',\n",
       "  'Explanation': 'Wakuluk’s model predicts that Country Z’s business cycle is currently in the late\\nupswing phase. In the late upswing phase, interest rates are typically rising as monetary\\npolicy becomes more restrictive. Cyclical assets may underperform, whereas the yield curve is\\nexpected to continue to flatten.',\n",
       "  'QA Type': 'Knowledge Reasoning QA',\n",
       "  'Question Type': 'text+image',\n",
       "  'Level of Difficulty': 'Easy',\n",
       "  'Knowledge Topics': 'Business cycles, Monetary policy, Yield curve',\n",
       "  'General Topics': 'Capital Market Expectations',\n",
       "  'Book Label': 'Capital Market Expectations',\n",
       "  'Model Answer': 'A',\n",
       "  'Model Reasoning': 'To determine the capital market effect for Country Z, we need to analyze its position in the business cycle as shown in the exhibit.\\n\\n1. **Identify Country Z\\'s Business Cycle Phase**: According to the exhibit, Country Z is in the \"Late Upswing\" phase.\\n\\n2. **Characteristics of the Late Upswing Phase**:\\n   - Economic activity is generally high, but growth may start to slow.\\n   - Inflationary pressures can build up, potentially leading to tighter monetary policy in the future.\\n   - Demand for cyclical assets, such as equities, often increases as investors seek higher returns.\\n\\n3. **Evaluate the Options**:\\n   - **Option A**: \"Cyclical assets attract investors.\" In the late upswing, as economic conditions are favorable, investors often turn to cyclical assets to capitalize on remaining growth opportunities.\\n   - **Option B**: \"Monetary policy becomes restrictive.\" While this could occur if inflationary pressures are significant, it typically happens later, as the economy moves towards the peak.\\n   - **Option C**: \"The yield curve steepens substantially.\" This is more characteristic of earlier recovery phases when economic growth is accelerating.\\n\\nGiven that Country Z is in the \"Late Upswing\" phase, the most likely capital market effect is that cyclical assets attract investors.\\n\\nTherefore, the correct option is 【A】.',\n",
       "  'Filter': 1,\n",
       "  'shared_description': '',\n",
       "  'description': '',\n",
       "  '待处理': '',\n",
       "  'Train': ''}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "\n",
    "file_path = '/Volumes/Jennie/Reasoning/FinReasoning/output/gpt_4o_output.json'\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "filtered_data = [item for item in data if item.get(\"Answer\") != item.get(\"Model Answer\")]# 设置只跑部分数据\n",
    "filtered_data[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Markdown,Latex, display\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import faiss\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# 加载CLIP模型和处理器\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "#初始化数据库\n",
    "def init_faiss():\n",
    "    index = faiss.IndexFlatIP(1024)  # 使用内积度量\n",
    "    if index.ntotal==0:\n",
    "        # 初始化 Faiss 索引，使用内积 (dot product) 作为距离度量\n",
    "        pass\n",
    "    # 清空Faiss索引中的所有向量\n",
    "    else:\n",
    "        index.reset()\n",
    "    # 检查索引是否清空\n",
    "    print(\"Number of vectors after reset:\", index.ntotal)\n",
    "    return index\n",
    "def index_faiss(index, file_path):\n",
    "    # 检查文件是否存在\n",
    "    if os.path.exists(file_path):\n",
    "        # 文件存在，加载数据\n",
    "        data = json.loads(Path(file_path).read_text())\n",
    "    else:\n",
    "        # 文件不存在，创建一个新的空列表\n",
    "        data =     [{\"ID\": 9999,\"Question Number\": 9999,\"Share Context\": \"\",\"Share Image\": \"\",\"Question Text\": \"text\",\"Image\": \"images/QuantitativeAnalysis1_images/40u.png\",\n",
    "                     \"Options\": {\"A\": \" -0.215\",\"B\": \" -0.113\",\"C\": \" 0.113\",\"D\": \" 0.215\"},\"Answer\": \"C\",\"Explanation\": \"text\",\"QA Type\": \"text\",\"Question Type\": \"text\",\"Level of Difficulty\": \"text\",\n",
    "                    \"Knowledge Topics\": \"text\",\"General Topics\":\"text\",\"Book Label\": \"text\",\"Model Answer\": \"C\",\"Model Reasoning\": \"text\",\"Feedback\": \"text\"\n",
    "                    }]\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    # 处理数据\n",
    "    for error in data:\n",
    "        storeEmbedding(index, error)\n",
    "\n",
    "    print(\"Number of vectors after adding:\", index.ntotal)\n",
    "    return index\n",
    "def clipEmbedding(data):\n",
    "    textdata = \"Question:\" + data.get(\"Question Text\") + \" Options:\" + str(data.get(\"Options\")) + \" Correct Answer:\" + data.get(\"Answer\")\n",
    "    \n",
    "    # 检查是否有图片\n",
    "    if data.get(\"Image\") != '':\n",
    "        image_path = \"/Volumes/Jennie/Reasoning/FinReasoning/dataset/\"+ data.get(\"Image\")\n",
    "        # print(image_path)\n",
    "        image = Image.open(image_path)\n",
    "        # print(image)\n",
    "        \n",
    "        # 生成文本和图像的嵌入，添加 truncation=True 和 max_length=77\n",
    "        inputs = processor(text=[textdata], images=image, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        \n",
    "        # 使用CLIP模型生成嵌入\n",
    "        outputs = model(**inputs)\n",
    "        image_embedding = outputs.image_embeds  # 图像嵌入\n",
    "        text_embedding = outputs.text_embeds  # 文本嵌入\n",
    "    else:\n",
    "        # 如果没有图像，生成文本嵌入\n",
    "        inputs = processor(text=[textdata], return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        text_embedding = model.get_text_features(**inputs)\n",
    "        \n",
    "        # 创建一个与图像嵌入维度相同的零向量\n",
    "        image_embedding = torch.zeros((text_embedding.shape[0], 512))  # 假设图像嵌入维度是512\n",
    "    \n",
    "    # 将文本和图像嵌入拼接在一起\n",
    "    combined_embedding = torch.cat((text_embedding, image_embedding), dim=-1)\n",
    "    \n",
    "    return combined_embedding\n",
    "\n",
    "\n",
    "def normalize(embeddings):\n",
    "    # 归一化函数，计算余弦相似度时将向量进行归一化\n",
    "    norms = torch.norm(embeddings, dim=1, keepdim=True)  # 计算每个向量的范数\n",
    "    return embeddings / norms  # 将向量归一化，使其范数变为1\n",
    "\n",
    "\n",
    "# 生成嵌入\n",
    "def storeEmbedding(index,data):\n",
    "    error_log_embedding = clipEmbedding(data)\n",
    "    # 对嵌入进行归一化，以便计算余弦相似度\n",
    "    error_log_embedding = normalize(error_log_embedding)\n",
    "    # 将生成的多模态嵌入转换为numpy数组并添加到Faiss索引中\n",
    "    error_log_embedding_np = error_log_embedding.detach().numpy()  # 确保转换为numpy格式\n",
    "    index.add(error_log_embedding_np)  # 将嵌入添加到Faiss索引中\n",
    "    return index\n",
    "\n",
    "# 查询函数\n",
    "def query_embedding_faiss(query_data, index, k=5):\n",
    "    # 生成查询嵌入\n",
    "    query_embedding = clipEmbedding(query_data)\n",
    "    query_embedding = normalize(query_embedding)  # 归一化查询向量\n",
    "    \n",
    "    # 转换为 numpy 格式\n",
    "    query_embedding_np = query_embedding.detach().numpy()\n",
    "    \n",
    "    # 检索 Faiss 中与查询向量最相似的 k 个向量\n",
    "    D, I = index.search(query_embedding_np, k)  # D 是余弦相似度，I 是对应的索引\n",
    "\n",
    "    \n",
    "    return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=init_faiss()# 初始化数据库\n",
    "index_faiss(index,ErrorLogPath) #把现在的errorlog加入到向量数据库\n",
    "\n",
    "for question in data:\n",
    "    # reasoning_first=chain.invoke(inputPrompt(question))\n",
    "    # answer_first=extract_answer(reasoning)    \n",
    "\n",
    "    # modelOutput=question\n",
    "    # modelOutput[\"Model Answer\"]=answer_first\n",
    "    # modelOutput[\"Model Reasoning\"]=reasoning_first\n",
    "    # write_output(modelOutput, ModelOutputPath)\n",
    "\n",
    "    if answer_first == question[\"Answer\"]:\n",
    "        write_output(modelOutput, ModelRAGOutputPath)\n",
    "    # else:\n",
    "    #     cos,I = query_embedding_faiss(question, index, k=5)\n",
    "    #     erroRLog=json.loads(Path(ErrorLogPath).read_text())\n",
    "    #     errorexample=erroRLog[I[0][0]]\n",
    "    #     reasoning_second=chain.invoke(ICLPrompt(question,errorexample))\n",
    "    #     answer_second=extract_answer(reasoning)\n",
    "    #     display(Markdown(reasoning))\n",
    "    #     print(\"=====================================\")\n",
    "    #     modelOutput[\"Model Answer\"]=answer_second\n",
    "    #     modelOutput[\"Model Reasoning\"]=reasoning_second  \n",
    "    #     write_output(modelOutput, ModelRAGOutputPath) \n",
    "\n",
    "        modelOutput[\"Model Answer\"]=answer_first\n",
    "        modelOutput[\"Model Reasoning\"]=reasoning_first\n",
    "        feedback=chain.invoke(FeedbackPrompt(modelOutput))\n",
    "        modelOutput[\"Feedback\"]=feedback\n",
    "        write_output(modelOutput, ErrorLogPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the JSON data from ModelOutputPath\n",
    "model_output_path = Path(ModelOutputPath)\n",
    "data1 = json.loads(model_output_path.read_text())\n",
    "df1 = pd.DataFrame(data1)\n",
    "model_output_path = Path(ModelRAGOutputPath)\n",
    "data2 = json.loads(model_output_path.read_text())\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eva_file_path):\n",
    "    data=json.loads(Path(eva_file_path).read_text())\n",
    "    a=0\n",
    "    for question in data:\n",
    "        if question[\"Model Answer\"] == question[\"Answer\"]:\n",
    "            a+=1\n",
    "        else:\n",
    "            a+=0\n",
    "    accuracy=a/len(data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7061281337047354 0.7771587743732591\n"
     ]
    }
   ],
   "source": [
    "data1 = evaluate(ModelOutputPath)\n",
    "data2 = evaluate(ModelRAGOutputPath)\n",
    "print(data1,data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
