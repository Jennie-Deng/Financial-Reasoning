{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist=[17, 31, 88, 125, 128, 131, 147, 150, 183, 184, 185, 186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 211, 212, 213, 215, 216, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 233, 234, 235, 236, 237, 239, 240, 241, 242, 254, 300, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 422, 423, 424, 425, 426, 427, 429, 430, 431, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 466, 478, 486, 492, 533, 535, 536, 547, 564, 638, 663, 664, 665, 666, 667, 669, 674, 676, 677, 678, 680, 681, 682, 684, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696, 697, 699, 709, 719, 728, 729, 736, 738, 740, 761, 763, 775, 776, 841, 851, 860, 863, 867, 872, 930, 931, 935, 936, 942, 946, 951, 966, 967, 971, 972, 974, 976, 977, 990, 998, 1029, 1040, 1042, 1082, 1083, 1088, 1110, 1114, 1123, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1145, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1166, 1167, 1168, 1175, 1176, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1197, 1198, 1199, 1200, 1201, 1202, 1211, 1212, 1213, 1214, 1215, 1216, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1227, 1228, 1229, 1230, 1244, 1245, 1268, 1288, 1301, 1318, 1330, 1345, 1418, 1424, 1425, 1427, 1430, 1433, 1435, 1437, 1442, 1447, 1448, 1451, 1468, 1489, 1493, 1503, 1504, 1505, 1507, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1586, 1681, 1686, 1697, 1784, 1790, 1806, 1866, 1874, 1926, 1954, 1968, 1973, 1994, 1999, 2000, 2001, 2002, 2003, 2004, 2006, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2027, 2034, 2042, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2054, 2055, 2056, 2057, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2067, 2068, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2093, 2094, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2119, 2132, 2133, 2136, 2142, 2143, 2148, 2163, 2165, 2166, 2167, 2189, 2193, 2202, 2205, 2214, 2218, 2219, 2231, 2238, 2262, 2264, 2266, 2269, 2271, 2298, 2308, 2309, 2310, 2311, 2316, 2317, 2320, 2322, 2326, 2342, 2348, 2352, 2358, 2366, 2375, 2384, 2392, 2397, 2398, 2400, 2401, 2406, 2433, 2449, 2458, 2477, 2647, 2648, 2650, 2658, 2661, 2662, 2689, 2695, 2701, 2714, 2715, 2716, 2718, 2719, 2720, 2722, 2723, 2724, 2725, 2727, 2728, 2730, 2731, 2732, 2733, 2734, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2746, 2747, 2748, 2749, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2766, 2767, 2768, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2793, 2794, 2795, 2796, 2798, 2799, 2800, 2802, 2803, 2804, 2806, 2807, 2808, 2809, 2811, 2816, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2845, 2861, 2873, 2875, 2895, 2897, 2903, 2914, 2917, 2920, 2950, 2951, 2991, 3001, 3011, 3013, 3022, 3023, 3024, 3032, 3044, 3062, 3089, 3097, 3099, 3108, 3116, 3119, 3120, 3121, 3122, 3129, 3142, 3151, 3152, 3153, 3155, 3156, 3163, 3174, 3181, 3186, 3188, 3190, 3222, 3235, 3240, 3243, 3250, 3257, 3261, 3269, 3282, 3285, 3302, 3304, 3308, 3322, 3354, 3355, 3361, 3396, 3429, 3501, 3552, 3635, 3673, 3711]\n",
    "len(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "        \"claude_sonnet\",\"claude_sonnet_rag\",\n",
    "        \"gpt_o1\",\"gpt_o1_rag\",\n",
    "        \"Gemini_Pro1\",\"Gemini_Pro1_rag\",\n",
    "        \"deepseek\",\"deepseek_rag\",\n",
    "        \"llama\",\"llama_rag\",\n",
    "        \"qwen\",\"qwen_rag\",\n",
    "\n",
    "        \"gpt_4o\",\"gpt_4o_rag\",\n",
    "        \"gemini_1.5_pro\",\"gemini_1.5_pro_rag\",\n",
    "        \"claude_3.5\",\"claude_3.5_rag\",\n",
    "        \"qwen2_vl\",\"qwen2_vl_rag\",\n",
    "        \"Llava\",\"Llava_rag\",\n",
    "        \"Llama_3.2_vision\",\"Llama_3.2_vision_rag\",\n",
    "        \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_path (model):\n",
    "    filePath=f\"/Users/sden118/Desktop/FinReasoning/output/{model}_output.json\"\n",
    "    return filePath\n",
    "def file_path_out (model):\n",
    "    filePathout=f\"/Users/sden118/Desktop/FinReasoning/test/{model}_test.json\"\n",
    "    return filePathout\n",
    "\n",
    "def write_output(data, file_path):\n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    data_list = data.to_dict(orient='records')\n",
    "\n",
    "    # If the file exists, delete it\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Write the data to the JSON file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_list, f, ensure_ascii=False, indent=4)\n",
    "# def write_output(data, file_path):\n",
    "#     # Convert DataFrame to list of dictionaries\n",
    "#     data_list = data.to_dict(orient='records')\n",
    "\n",
    "#     # If the file exists, read the existing data\n",
    "#     if os.path.exists(file_path):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             existing_data = json.load(f)\n",
    "#     else:\n",
    "#         existing_data = []\n",
    "\n",
    "#     # Merge new data into existing data\n",
    "#     if isinstance(existing_data, list):\n",
    "#         existing_data.extend(data_list)\n",
    "#     else:\n",
    "#         existing_data = data_list\n",
    "\n",
    "#     # Write the merged data back to the JSON file\n",
    "#     with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(existing_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a Python dictionary\n",
    "with open(\"/Users/sden118/Desktop/FinReasoning/dataset/data_v5.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "for i in range(0, len(data)):\n",
    "    if data[i][\"ID\"] in testlist:\n",
    "        data[i][\"Datasplit\"] = \"test\"\n",
    "    else:\n",
    "        data[i][\"Datasplit\"] = \"train\"\n",
    "data6=pd.DataFrame(data)\n",
    "data6=data6[['ID', 'Share Context', 'Share Image','Question Text', 'Image', 'Options', 'Answer', 'Explanation', 'QA Type', 'Level of Difficulty','shared_description', 'description', 'Datasplit']]\n",
    "# data6['Index'] = data6.index\n",
    "for index, entry in data6.iterrows():\n",
    "    if (entry[\"Share Context\"] != \"\") and (entry[\"Share Image\"] == \"\"):\n",
    "        a = \"images/image_add/\" + str(entry[\"ID\"]) + \".png\"\n",
    "        data6.at[index, \"Share Image\"] = [a]\n",
    "    if (entry[\"Share Context\"] == \"\") and (entry[\"Image\"] == \"\"):\n",
    "        data6.at[index, \"Image\"] = \"images/image_add/\" + str(entry[\"ID\"]) + \".png\"\n",
    "\n",
    "data6.to_csv(\"/Users/sden118/Desktop/FinReasoning/dataset/data_v6.csv\", index=False)\n",
    "write_output(data6, \"/Users/sden118/Desktop/FinReasoning/dataset/data_v6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "data6=pd.read_json(\"/Users/sden118/Desktop/FinReasoning/dataset/data_v6.json\")\n",
    "for entry in data6.iterrows():\n",
    "    print(entry[1][\"ID\"])\n",
    "    if (entry[1][\"Share Image\"] != \"\"):\n",
    "        for i in range(0, len(entry[1][\"Share Image\"])):\n",
    "            display(Image.open(entry[1][\"Share Image\"][i]))\n",
    "    if entry[1][\"Image\"] != \"\":\n",
    "        display(Image.open(entry[1][\"Image\"]))\n",
    "    print(\"**\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sden118/Desktop/FinReasoning/test/claude_sonnet_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/claude_sonnet_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_o1_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_o1_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Gemini_Pro1_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Gemini_Pro1_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/deepseek_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/deepseek_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/llama_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/llama_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_4o_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_4o_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gemini_1.5_pro_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gemini_1.5_pro_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/claude_3.5_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/claude_3.5_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen2_vl_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen2_vl_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llava_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llava_rag_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llama_3.2_vision_test.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llama_3.2_vision_rag_test.json\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    df = pd.read_json(file_path(model))\n",
    "    df=df[['ID', 'Share Context', 'Share Image','Question Text', 'Image', 'Options', 'Answer', 'Explanation', 'QA Type', 'Level of Difficulty','shared_description', 'description',\"Model Answer\",\"Model Reasoning\"]]\n",
    "    df=df[df[\"ID\"].isin(testlist)]\n",
    "    df[\"Datasplit\"]=\"test\"\n",
    "    filePathout=file_path_out(model)\n",
    "    print(filePathout)\n",
    "    write_output(df, filePathout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error log 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=[\n",
    "        \"claude_sonnet\",\n",
    "        \"gpt_o1\",\n",
    "        \"Gemini_Pro1\",\n",
    "        \"deepseek\",\n",
    "        \"llama\",\n",
    "        \"qwen\",\n",
    "\n",
    "        \"gpt_4o\",\n",
    "        \"gemini_1.5_pro\",\n",
    "        \"claude_3.5\",\n",
    "        \"qwen2_vl\",\n",
    "        \"Llava\",\n",
    "        \"Llama_3.2_vision\",\n",
    "        \n",
    "        ]\n",
    "def log_file_path (model):\n",
    "    filePath=f\"/Users/sden118/Desktop/FinReasoning/errorLog/{model}_ErrorLog.json\"\n",
    "    return filePath\n",
    "def log_file_path_out (model):\n",
    "    filePathout=f\"/Users/sden118/Desktop/FinReasoning/test/{model}_ErrorLog.json\"\n",
    "    return filePathout       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=pd.read_json(\"/Users/sden118/Desktop/FinReasoning/errorLog/claude_sonnet_ErrorLog.json\")\n",
    "dd1=pd.read_json(\"/Users/sden118/Desktop/FinReasoning/output/claude_sonnet_output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df)):\n",
    "    df['ID'].iloc[i]\n",
    "    df['Model Answer'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sden118/Desktop/FinReasoning/test/claude_sonnet_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_o1_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Gemini_Pro1_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/deepseek_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/llama_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gpt_4o_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/gemini_1.5_pro_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/claude_3.5_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/qwen2_vl_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llava_ErrorLog.json\n",
      "/Users/sden118/Desktop/FinReasoning/test/Llama_3.2_vision_ErrorLog.json\n"
     ]
    }
   ],
   "source": [
    "for model in logs:\n",
    "    df = pd.read_json(log_file_path(model))\n",
    "    df = df[['ID', 'Question Number', 'Share Context', 'Share Image',\n",
    "             'Question Text', 'Image', 'Options', 'Answer', 'Explanation', 'QA Type',\n",
    "             'Question Type', 'Level of Difficulty', 'Model Answer', 'Model Reasoning',\n",
    "             'Feedback', 'shared_description', 'description']]\n",
    "    \n",
    "    df1 = pd.read_json(file_path(model))\n",
    "    \n",
    "    # Merge df and df1 on 'ID' to get the 'model reasoning' column from df1\n",
    "    merged_df = df.merge(df1[['ID', 'Model Reasoning']], on='ID', how='left')\n",
    "    \n",
    "    # Replace 'Model Reasoning' column in df with 'model reasoning' from merged_df\n",
    "    df['Model Reasoning'] = merged_df['Model Reasoning_y']\n",
    "    \n",
    "    filePathout = log_file_path_out(model)\n",
    "    print(filePathout)\n",
    "    write_output(df, filePathout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
